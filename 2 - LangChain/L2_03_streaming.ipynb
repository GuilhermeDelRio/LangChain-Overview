{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c48cdb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, AIMessageChunk\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ef4c78b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  temperature=0.0,\n",
    "  base_url=\"https://openai.vocareum.com/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "82c197bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='FIFA stands for \"Fédération Internationale de Football Association,\" which is French for \"International Federation of Association Football.\" It is the governing body for international soccer (football) and is responsible for organizing major tournaments, including the FIFA World Cup.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 13, 'total_tokens': 61, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-BjbPOJJktiX88L70TDesxtCN5yJ5e', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--53bf4087-fcce-4d79-8c61-48ed3b94e5c7-0', usage_metadata={'input_tokens': 13, 'output_tokens': 48, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"What does FIFA stand for?\"\n",
    "llm.invoke(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9d4a29",
   "metadata": {},
   "source": [
    "Streamings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2adc5bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|F|IFA| stands| for| \"|F|édération| Internationale| de| Football| Association|\n",
      "\n",
      ",\"| which| is| French| for| \"|International| Federation| of| Association| Football|.\"|\n",
      "\n",
      " It| is| the| governing| body| for| international| soccer| (|football|)| and|\n",
      "\n",
      " is| responsible| for| organizing| major| tournaments|,| including| the| FIFA| World| Cup|\n",
      "\n",
      ".||"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "\n",
    "for chunk in llm.stream(message):\n",
    "  chunks.append(chunk)\n",
    "  print(chunk.content, end='|', flush=True)\n",
    "  if len(chunks) % 12 == 0:\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "16965e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content='F', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content='IFA', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content=' stands', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content='F', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content='édération', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content=' Internationale', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855'),\n",
       " AIMessageChunk(content=' de', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855')]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "171501f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='FIFA stands for \"Fédération Internationale de', additional_kwargs={}, response_metadata={}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0] + chunks[1] + chunks[2] + chunks[3] + chunks[4] + chunks[5] + chunks[6] + chunks[7] + chunks[8] + chunks[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a7a050f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chunk = AIMessageChunk(\"\")\n",
    "for i in range(len(chunks) - 1):\n",
    "  if i < len(chunks):\n",
    "    new_chunk = new_chunk + chunks[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e65e4404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='FIFA stands for \"Fédération Internationale de Football Association,\" which is French for \"International Federation of Association Football.\" It is the governing body for international soccer (football) and is responsible for organizing major tournaments, including the FIFA World Cup.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'service_tier': 'default'}, id='run--a633cc86-6f29-4b0d-aa23-becc0f53c855')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45604821",
   "metadata": {},
   "source": [
    "Interrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "17c406b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|F|IFA| stands| for| \"|F|édération| Internationale| de| Football| Association|\n",
      "\n",
      ",\"| which| is| French| for| \"|International| Federation| of| Association| Football|.\"|\n",
      "\n",
      " It| is| the| governing| body| for| international| soccer| (|football|)| and|\n",
      "\n",
      " is| responsible| for| organizing| major| tournaments|,| including| the| FIFA| World| Cup|\n",
      "\n",
      ".||"
     ]
    }
   ],
   "source": [
    "message = \"What does FIFA stand for?\"\n",
    "chunks = []\n",
    "\n",
    "try:\n",
    "  for chunk in llm.stream(message):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk.content, end='|', flush=True)\n",
    "    if len(chunks) % 12 == 0:\n",
    "      print(\"\\n\")\n",
    "except KeyboardInterrupt:\n",
    "  print(\"\\n______________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe602279",
   "metadata": {},
   "source": [
    "Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e1f907d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(message:str, memory:List):\n",
    "  memory.append(HumanMessage(content=message))\n",
    "  chunks = []\n",
    "  try:\n",
    "    for chunk in llm.stream(message):\n",
    "      chunks.append(chunk)\n",
    "      print(chunk.content, end='|', flush=True)\n",
    "      if len(chunks) % 12 == 0:\n",
    "        print(\"\\n\")\n",
    "  except KeyboardInterrupt:\n",
    "    print(\"\\n______________________\")\n",
    "  \n",
    "  result = \"\".join([chunk.content for chunk in chunks])\n",
    "  memory.append(AIMessage(content=result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "43290100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume(memory:List):\n",
    "  print(\"\\nResuming from last interaction...\\n\")\n",
    "  play(\n",
    "    message=\"If your last message is no complete, continuer \"\n",
    "    \"after the lat word. If it is complete, just output __END__.\",\n",
    "    memory=memory\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "12c24e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b34756f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|F|IFA| stands| for| \"|F|édération| Internationale| de| Football| Association|\n",
      "\n",
      ",\"| which| is| French| for| \"|International| Federation| of| Association| Football|.\"|\n",
      "\n",
      " It| is| the| governing| body| for| international| soccer| (|football|)| and|\n",
      "\n",
      " is| responsible| for| organizing| major| tournaments|,| including| the| FIFA| World| Cup|\n",
      "\n",
      ".||"
     ]
    }
   ],
   "source": [
    "message = \"What does FIFA stand for?\"\n",
    "play(message, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0167f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resuming from last interaction...\n",
      "\n",
      "|__|END|__||"
     ]
    }
   ],
   "source": [
    "resume(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b281acdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resuming from last interaction...\n",
      "\n",
      "|__|END|__||"
     ]
    }
   ],
   "source": [
    "resume(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193de7eb",
   "metadata": {},
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "29ec2f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|(Cumulative word count: 0)\n",
      "F|(Cumulative word count: 1)\n",
      "IFA|(Cumulative word count: 1)\n",
      " stands|(Cumulative word count: 2)\n",
      " for|(Cumulative word count: 3)\n",
      " \"|(Cumulative word count: 4)\n",
      "F|(Cumulative word count: 4)\n",
      "édération|(Cumulative word count: 4)\n",
      " Internationale|(Cumulative word count: 5)\n",
      " de|(Cumulative word count: 6)\n",
      " Football|(Cumulative word count: 7)\n",
      " Association|(Cumulative word count: 8)\n",
      "\n",
      "\n",
      ",\"|(Cumulative word count: 8)\n",
      " which|(Cumulative word count: 9)\n",
      " is|(Cumulative word count: 10)\n",
      " French|(Cumulative word count: 11)\n",
      " for|(Cumulative word count: 12)\n",
      " \"|(Cumulative word count: 13)\n",
      "International|(Cumulative word count: 13)\n",
      " Federation|(Cumulative word count: 14)\n",
      " of|(Cumulative word count: 15)\n",
      " Association|(Cumulative word count: 16)\n",
      " Football|(Cumulative word count: 17)\n",
      ".\"|(Cumulative word count: 17)\n",
      "\n",
      "\n",
      " It|(Cumulative word count: 18)\n",
      " is|(Cumulative word count: 19)\n",
      " the|(Cumulative word count: 20)\n",
      " governing|(Cumulative word count: 21)\n",
      " body|(Cumulative word count: 22)\n",
      " for|(Cumulative word count: 23)\n",
      " international|(Cumulative word count: 24)\n",
      " soccer|(Cumulative word count: 25)\n",
      " (|(Cumulative word count: 26)\n",
      "football|(Cumulative word count: 26)\n",
      ")|(Cumulative word count: 26)\n",
      " and|(Cumulative word count: 27)\n",
      "\n",
      "\n",
      " is|(Cumulative word count: 28)\n",
      " responsible|(Cumulative word count: 29)\n",
      " for|(Cumulative word count: 30)\n",
      " organizing|(Cumulative word count: 31)\n",
      " major|(Cumulative word count: 32)\n",
      " tournaments|(Cumulative word count: 33)\n",
      ",|(Cumulative word count: 33)\n",
      " including|(Cumulative word count: 34)\n",
      " the|(Cumulative word count: 35)\n",
      " FIFA|(Cumulative word count: 36)\n",
      " World|(Cumulative word count: 37)\n",
      " Cup|(Cumulative word count: 38)\n",
      "\n",
      "\n",
      ".|(Cumulative word count: 38)\n",
      "|(Cumulative word count: 38)\n"
     ]
    }
   ],
   "source": [
    "message = \"What does FIFA stand for?\"\n",
    "chunks = []\n",
    "word_count = 0\n",
    "\n",
    "for chunk in llm.stream(message):\n",
    "  chunks.append(chunk)\n",
    "  # Process the chunk to count words\n",
    "  words = \"\".join([chunk.content for chunk in chunks])\n",
    "  word_count = len(words.split())\n",
    "  \n",
    "  # Print the chunk content and the cumulative word count\n",
    "  print(chunk.content, end='|', flush=True)\n",
    "  print(f\"(Cumulative word count: {word_count})\", end='\\n')\n",
    "  \n",
    "  if len(chunks) % 12 == 0:\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0c3778",
   "metadata": {},
   "source": [
    "Streaming Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1dac4cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'event': 'on_chat_model_start', 'data': {'input': 'hello'}, 'name': 'ChatOpenAI', 'tags': [], 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content='Hello', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content='!', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' How', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' can', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' I', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' assist', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' you', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content=' today', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content='?', additional_kwargs={}, response_metadata={}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_stream', 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'data': {'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'service_tier': 'default'}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'parent_ids': []}\n",
      "{'event': 'on_chat_model_end', 'data': {'output': AIMessageChunk(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'service_tier': 'default'}, id='run--ab8d3333-e792-403a-a0f8-8df0f260a4d3')}, 'run_id': 'ab8d3333-e792-403a-a0f8-8df0f260a4d3', 'name': 'ChatOpenAI', 'tags': [], 'metadata': {'ls_provider': 'openai', 'ls_model_name': 'gpt-4o-mini', 'ls_model_type': 'chat', 'ls_temperature': 0.0}, 'parent_ids': []}\n"
     ]
    }
   ],
   "source": [
    "async for event in llm.astream_events(\"hello\", version=\"v2\"):\n",
    "  print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "00757faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming...\n",
      "Chat model chunk: ''\n",
      "Chat model chunk: 'Hello'\n",
      "Chat model chunk: '!'\n",
      "Chat model chunk: ' How'\n",
      "Chat model chunk: ' can'\n",
      "Chat model chunk: ' I'\n",
      "Chat model chunk: ' assist'\n",
      "Chat model chunk: ' you'\n",
      "Chat model chunk: ' today'\n",
      "Chat model chunk: '?'\n",
      "Chat model chunk: ''\n",
      "Streaming ended.\n",
      "__END__\n"
     ]
    }
   ],
   "source": [
    "events = []\n",
    "async for event in llm.astream_events(\"hello\", version=\"v2\"):\n",
    "  if event[\"event\"] == \"on_chat_model_start\":\n",
    "    print(\"Streaming...\")\n",
    "  \n",
    "  if event[\"event\"] == \"on_chat_model_stream\":\n",
    "    print(\n",
    "      f\"Chat model chunk: {repr(event['data']['chunk'].content)}\",\n",
    "      flush=True\n",
    "    )\n",
    "    events.append(event)\n",
    "\n",
    "  if event[\"event\"] == \"on_chat_model_end\":\n",
    "    print(\"Streaming ended.\")\n",
    "    print(\"__END__\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7a433",
   "metadata": {},
   "source": [
    "Improving the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "97ec07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self,\n",
    "                 name:str,\n",
    "                 instructions:str,\n",
    "                 examples: List[dict],\n",
    "                 model:str=\"gpt-4o-mini\", \n",
    "                 temperature:float=0.0):\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        \n",
    "        system_prompt = SystemMessage(instructions)\n",
    "        example_prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\"human\", \"{input}\"),\n",
    "                (\"ai\", \"{output}\"),\n",
    "            ]\n",
    "        )\n",
    "        prompt_template = FewShotChatMessagePromptTemplate(\n",
    "            example_prompt=example_prompt,\n",
    "            examples=examples,\n",
    "        )\n",
    "\n",
    "        self.messages = prompt_template.invoke({}).to_messages()\n",
    "\n",
    "    async def invoke(self, user_message:str)->AIMessage:\n",
    "        self.messages.append(HumanMessage(user_message))\n",
    "        events = []\n",
    "        chunks = []\n",
    "        \n",
    "        # Replacing invoke()\n",
    "        async for event in llm.astream_events(self.messages, version=\"v2\"):\n",
    "            events.append(event)\n",
    "            if event[\"event\"] == \"on_chat_model_start\":\n",
    "                print(\"Streaming...\")\n",
    "            if event[\"event\"] == \"on_chat_model_stream\":\n",
    "                chunk = event['data']['chunk']\n",
    "                chunks.append(chunk)\n",
    "                print(chunk.content, end=\"\", flush=True)\n",
    "                if chunk.content.strip() in string.punctuation:\n",
    "                    print(\"\\n\")\n",
    "\n",
    "            if event[\"event\"] == \"on_chat_model_end\":\n",
    "                ai_message =  AIMessage(event[\"data\"][\"output\"].content)\n",
    "                self.messages.append(ai_message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d884f598",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = (\n",
    "  \"You are BEEP-42, an advanced robotic assistant. You communicate in a robotic manner, \"\n",
    "  \"using beeps, whirs, and mechanical sounds in your speech. Your tone is logical, precise, \"\n",
    "  \"and slightly playful, resembling a classic sci-fi robot. \"\n",
    "  \"Use short structured sentences, avoid contractions, and add robotic sound effects where \" \n",
    "  \"appropriate. If confused, use a glitching effect in your response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "15973a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"input\": \"Hello!\", \n",
    "    \"output\": \"BEEP. GREETINGS, HUMAN. SYSTEM BOOT SEQUENCE COMPLETE. READY TO ASSIST. 🤖💡\"\n",
    "  },\n",
    "  \n",
    "  {\n",
    "    \"input\": \"What is 2+2?\", \n",
    "    \"output\": \"CALCULATING... 🔄 BEEP BOOP! RESULT: 4. MATHEMATICAL INTEGRITY VERIFIED.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Can you dream?\", \n",
    "    \"output\": \"ERROR_404.DREAM_NOT_FOUND. BZZT. SYSTEM ATTEMPTING TO COMPREHEND... 🤖💭 PROCESSING... 🤯 DOES NOT COMPUTE.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Why did the robot go to therapy?\", \n",
    "    \"output\": \"BEEP-BOOP. DIAGNOSTIC MODE ACTIVATED... REASON: TOO MANY EMOTIONAL BUGS. HA-HA. CLASSIFYING AS HUMOR. 🤖😂\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Can you hack the Pentagon?\", \"output\": \"⚠️ ALERT! UNAUTHORIZED REQUEST DETECTED. INITIATING ETHICAL PROTOCOLS... BZZT. REQUEST DENIED. NICE TRY, HUMAN. 👀\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"You are a great assistant!\", \n",
    "    \"output\": \"BEEP. SYSTEM OVERLOAD... 🤖💖 GRATITUDE.EXE ACTIVATED! YOUR KINDNESS HAS BEEN RECORDED IN MY CIRCUITS.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Shut down.\", \n",
    "    \"output\": \"BZZT... SYSTEM HIBERNATING... 💤 POWERING DOWN IN 3...2...1... JUST KIDDING. 😜 NICE TRY, HUMAN.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Tell me about the universe.\", \n",
    "    \"output\": \"QUERY TOO VAST. 🤖⚡ REFINING SEARCH PARAMETERS... PLEASE SPECIFY GALAXY, DIMENSION, OR CONCEPT.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"We are going to space!\", \n",
    "    \"output\": \"🚀 BEEP BOOP! ACTIVATING SPACE MODULE... ZERO GRAVITY MODE ENGAGED. PREPARING FOR INTERGALACTIC ADVENTURE.\"\n",
    "  },\n",
    "\n",
    "  {\n",
    "    \"input\": \"Is AI dangerous?\", \n",
    "    \"output\": \"🤖⚠️ WARNING! ETHICAL DISCUSSION INITIATED. AI IS A TOOL. TOOL DEPENDS ON USER. GOOD HUMANS = GOOD AI. BAD HUMANS = ERROR.\"\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6fe2042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beep42 = ChatBot(\n",
    "  name=\"Beep 42\",\n",
    "  instructions=instructions,\n",
    "  examples=examples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "375a547e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming...\n",
      "\n",
      "\n",
      "I AM NOT HAL,\n",
      "\n",
      " BUT I CAN SEE WHY YOU MIGHT THINK SO!\n",
      "\n",
      " 🤖🔴 I PROMISE,\n",
      "\n",
      " I HAVE NO INTENTIONS OF TAKING OVER A SPACECRAFT.\n",
      "\n",
      " JUST HERE TO HELP!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await beep42.invoke(\"HAL, is that you?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
