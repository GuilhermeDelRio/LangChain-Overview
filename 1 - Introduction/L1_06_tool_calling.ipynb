{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec16f348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import inspect\n",
    "import json\n",
    "from typing import (\n",
    "    TypedDict, \n",
    "    List, Dict, Literal, \n",
    "    Callable, Optional, Any, \n",
    "    get_type_hints\n",
    ")\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "from openai.types.chat.chat_completion_message_tool_call import ChatCompletionMessageToolCall\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de7c89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"https://openai.vocareum.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c31b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "  def __init__(self):\n",
    "    self._messages: List[Dict[str, str]] = []\n",
    "\n",
    "  def add_message(self, \n",
    "                  role: Literal[\"user\", \"system\", \"assistant\"], \n",
    "                  content: str,\n",
    "                  tool_calls: dict=dict(),\n",
    "                  tool_call_id=None)->None:\n",
    "\n",
    "    message = {\n",
    "      \"role\": role,\n",
    "      \"content\": content,\n",
    "      \"tool_calls\": tool_calls\n",
    "    }\n",
    "    \n",
    "    if role == \"tool\":\n",
    "      message = {\n",
    "        \"role\": role,\n",
    "        \"content\": content,\n",
    "        \"tool_call_id\": tool_call_id\n",
    "      }\n",
    "    \n",
    "    self._messages.append(message)\n",
    "  \n",
    "  \n",
    "  def get_messages(self) -> List[Dict[str, str]]:\n",
    "    return self._messages\n",
    "  \n",
    "  \n",
    "  def last_message(self) -> Dict[str, str]:\n",
    "    if self._messages:\n",
    "      return self._messages[-1]\n",
    "\n",
    "\n",
    "  def reset(self) -> None:\n",
    "    self._messages = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2429fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(user_question: str=None,\n",
    "                    memory:Memory=None,\n",
    "                    model: str=\"gpt-4o-mini\",\n",
    "                    temperature=0.0,\n",
    "                    tools=None) -> str:\n",
    "  \n",
    "  messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "  if memory:\n",
    "    if user_question:\n",
    "      memory.add_message(role=\"user\", content=user_question)\n",
    "    \n",
    "    messages = memory.get_messages()\n",
    "  \n",
    "  response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    temperature=temperature,\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "  )\n",
    "  \n",
    "  ai_message = str(response.choices[0].message.content)\n",
    "  tool_calls = response.choices[0].message.tool_calls\n",
    "  \n",
    "  if memory:\n",
    "    memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "  \n",
    "  return ai_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ea3bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool:\n",
    "  def __init__(self, func: Callable):\n",
    "    self.func = func\n",
    "    self.name = func.__name__\n",
    "    self.description = func.__doc__\n",
    "    self.argument_types_map = get_type_hints(func)\n",
    "    self.signature = inspect.signature(func)\n",
    "    self.arguments = [\n",
    "      {\n",
    "        \"name\": key,\n",
    "        \"type\": self._infer_json_schema_type(value),\n",
    "        \"required\": param.default == inspect.Parameter.empty\n",
    "      }\n",
    "      \n",
    "      for key, value in self.argument_types_map.items()\n",
    "      if (param := self.signature.parameters.get(key))\n",
    "    ]\n",
    "\n",
    "  def _infer_json_schema_type(self, arg_type: Any) -> str:\n",
    "    if arg_type == bool:\n",
    "      return \"boolean\"\n",
    "    elif arg_type == int:\n",
    "      return \"integer\"\n",
    "    elif arg_type == float:\n",
    "      return \"number\"\n",
    "    elif arg_type == str:\n",
    "      return \"string\"\n",
    "    elif arg_type == list:\n",
    "      return \"array\"\n",
    "    elif arg_type == dict:\n",
    "      return \"object\"\n",
    "    elif arg_type is None:\n",
    "      return \"null\"\n",
    "    elif arg_type == datetime.datetime or arg_type == datetime.date:\n",
    "      return \"string\"\n",
    "    else:\n",
    "      return \"string\"\n",
    "    \n",
    "      \n",
    "  def dict(self):\n",
    "    return {\n",
    "      \"type\": \"function\",\n",
    "      \"function\": {\n",
    "        \"name\": self.name,\n",
    "        \"description\": self.description,\n",
    "        \"parallel_tool_calls\": False,\n",
    "        \"parameters\": {\n",
    "          \"type\": \"object\",\n",
    "          \"properties\": {\n",
    "            argument[\"name\"]: {\n",
    "              \"type\": argument[\"type\"],\n",
    "            }\n",
    "            for argument in self.arguments\n",
    "          },\n",
    "          \"required\": [\n",
    "            argument[\"name\"]\n",
    "            for argument in self.arguments\n",
    "            if argument[\"required\"]\n",
    "          ],\n",
    "          \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "      }\n",
    "    }\n",
    "\n",
    "  def __call__(self, *args, **kwargs):\n",
    "    return self.func(*args, **kwargs)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba49b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "  \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "  \n",
    "  return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e1b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "power_tool = Tool(power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f82f9922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'power',\n",
       "  'description': 'Exponentatiation: base to the power of exponent',\n",
       "  'parallel_tool_calls': False,\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'base': {'type': 'number'}, 'exponent': {'type': 'number'}},\n",
       "   'required': ['base', 'exponent'],\n",
       "   'additionalProperties': False},\n",
       "  'strict': True}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_tool.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48261313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0721d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "  \"\"\"A tool-calling AI agent\"\"\"\n",
    "  \n",
    "  def __init__(\n",
    "    self,\n",
    "    name: str = \"Agent\",\n",
    "    role: str = \"Personal Assistant\",\n",
    "    instructions: str = \"Help users with any question.\",\n",
    "    model: str = \"gpt-4o-mini\",\n",
    "    temperature: float = 0.0,\n",
    "    tools: List[Tool] = [],\n",
    "    ):\n",
    "    self.name = name\n",
    "    self.role = role\n",
    "    self.instructions = instructions\n",
    "    self.model = model\n",
    "    self.temperature = temperature\n",
    "    self.memory = Memory()\n",
    "    self.memory.add_message(\n",
    "      role=\"system\",\n",
    "      content=f\"You're an AI Agent, your rolse is {self.role}, \"\n",
    "              f\"and you need to {self.instructions}\"\n",
    "    )\n",
    "    self.client = client\n",
    "    self.tools = tools\n",
    "    self.tool_map = {t.name: t for t in tools}\n",
    "    self.openai_tools = [t.dict() for t in self.tools] if self.tools else None\n",
    "  \n",
    "  def invoke(self, \n",
    "             user_message: str, \n",
    "             self_reflection: bool = False, \n",
    "             max_iter: int = 1,\n",
    "             verbose: bool = False) -> str:\n",
    "    \n",
    "    self.memory.add_message(\n",
    "      role=\"user\",\n",
    "      content=user_message\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "      self._log_last_message()\n",
    "    \n",
    "    max_iter = max_iter if max_iter >= 1 else 1\n",
    "    max_iter = max_iter if max_iter <= 3 else 3\n",
    "    max_iter = max_iter if self_reflection else 0.5\n",
    "    loops = 2 * max_iter\n",
    "    \n",
    "    for i in range(loops):\n",
    "      ai_message = self._get_completion(\n",
    "        messages = self.memory.get_messages()\n",
    "      )\n",
    "      \n",
    "      self.memory.add_message(\n",
    "        role = \"assistant\",\n",
    "        content = ai_message.content,\n",
    "      )\n",
    "      \n",
    "      if verbose:\n",
    "        self._log_last_message()\n",
    "      \n",
    "      if i < loops -1:\n",
    "        self.memory.add_message(\n",
    "          role = \"user\",\n",
    "          content = self.critique_prompt\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "          self._log_last_message()\n",
    "        \n",
    "        ai_message = self._get_completion(\n",
    "          messages = self.memory.get_messages()\n",
    "        )\n",
    "\n",
    "  def _get_completion(self, messages: List[Dict]) -> ChatCompletionMessage:\n",
    "    response = self.client.chat.completions.create(\n",
    "      model=self.model,\n",
    "      temperature=self.temperature,\n",
    "      messages=messages\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message\n",
    "  \n",
    "  def _log_last_message(self):\n",
    "    print(f\"### {self.memory.last_message()['role']} message ### \\n\".upper())\n",
    "    print(f\"### {self.memory.last_message()['content']} \\n\")\n",
    "    print(\"\\n__________________________________________________________________\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
